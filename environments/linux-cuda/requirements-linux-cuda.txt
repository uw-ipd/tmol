#
# This file is autogenerated by pip-compile with Python 3.11
# by the following command:
#
#    pip-compile --no-emit-index-url ../../requirements.in
#
astor==0.8.1
    # via -r ../../requirements.in
asttokens==3.0.0
    # via stack-data
attrs==25.3.0
    # via
    #   -r ../../requirements.in
    #   attrs-strict
    #   cattrs
    #   hypothesis
attrs-strict==1.0.1
    # via -r ../../requirements.in
cattrs==24.1.3
    # via -r ../../requirements.in
certifi==2025.1.31
    # via requests
charset-normalizer==3.4.1
    # via requests
crc32c==2.7.1
    # via numcodecs
decorator==5.2.1
    # via
    #   -r ../../requirements.in
    #   ipython
donfig==0.8.1.post1
    # via zarr
executing==2.2.0
    # via stack-data
filelock==3.18.0
    # via torch
flexcache==0.3
    # via pint
flexparser==0.4
    # via pint
frozendict==2.4.6
    # via -r ../../requirements.in
fsspec==2025.3.2
    # via torch
hypothesis==6.131.8
    # via -r ../../requirements.in
idna==3.10
    # via requests
ipython==9.1.0
    # via -r ../../requirements.in
ipython-pygments-lexers==1.1.1
    # via ipython
jedi==0.19.2
    # via ipython
jinja2==3.1.6
    # via torch
llvmlite==0.44.0
    # via numba
markupsafe==3.0.2
    # via jinja2
matplotlib-inline==0.1.7
    # via ipython
mpmath==1.3.0
    # via sympy
mypy-extensions==1.1.0
    # via typing-inspect
networkx==3.4.2
    # via
    #   -r ../../requirements.in
    #   torch
ninja==1.11.1.4
    # via -r ../../requirements.in
numba==0.61.2
    # via sparse
numcodecs[crc32c]==0.16.0
    # via zarr
numpy==2.2.5
    # via
    #   -r ../../requirements.in
    #   numba
    #   numcodecs
    #   pandas
    #   scipy
    #   sparse
    #   zarr
nvidia-cublas-cu12==12.4.5.8
    # via
    #   nvidia-cudnn-cu12
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cuda-cupti-cu12==12.4.127
    # via torch
nvidia-cuda-nvrtc-cu12==12.4.127
    # via torch
nvidia-cuda-runtime-cu12==12.4.127
    # via torch
nvidia-cudnn-cu12==9.1.0.70
    # via torch
nvidia-cufft-cu12==11.2.1.3
    # via torch
nvidia-curand-cu12==10.3.5.147
    # via torch
nvidia-cusolver-cu12==11.6.1.9
    # via torch
nvidia-cusparse-cu12==12.3.1.170
    # via
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cusparselt-cu12==0.6.2
    # via torch
nvidia-nccl-cu12==2.21.5
    # via torch
nvidia-nvjitlink-cu12==12.4.127
    # via
    #   nvidia-cusolver-cu12
    #   nvidia-cusparse-cu12
    #   torch
nvidia-nvtx-cu12==12.4.127
    # via torch
packaging==25.0
    # via zarr
pandas==2.2.3
    # via -r ../../requirements.in
parso==0.8.4
    # via jedi
pexpect==4.9.0
    # via ipython
pint==0.24.4
    # via -r ../../requirements.in
platformdirs==4.3.7
    # via pint
prompt-toolkit==3.0.51
    # via ipython
psutil==7.0.0
    # via -r ../../requirements.in
ptyprocess==0.7.0
    # via pexpect
pure-eval==0.2.3
    # via stack-data
pyarrow==19.0.1
    # via -r ../../requirements.in
pygments==2.19.1
    # via
    #   ipython
    #   ipython-pygments-lexers
python-dateutil==2.9.0.post0
    # via pandas
pytz==2025.2
    # via pandas
pyyaml==6.0.2
    # via
    #   -r ../../requirements.in
    #   donfig
requests==2.32.3
    # via -r ../../requirements.in
scipy==1.15.2
    # via -r ../../requirements.in
six==1.17.0
    # via python-dateutil
sortedcontainers==2.4.0
    # via hypothesis
sparse==0.16.0
    # via -r ../../requirements.in
stack-data==0.6.3
    # via ipython
sympy==1.13.1
    # via torch
toolz==1.0.0
    # via -r ../../requirements.in
torch==2.6.0
    # via -r ../../requirements.in
traitlets==5.14.3
    # via
    #   ipython
    #   matplotlib-inline
triton==3.2.0
    # via torch
typing-extensions==4.13.2
    # via
    #   -r ../../requirements.in
    #   flexcache
    #   flexparser
    #   ipython
    #   numcodecs
    #   pint
    #   torch
    #   typing-inspect
    #   zarr
typing-inspect==0.9.0
    # via -r ../../requirements.in
tzdata==2025.2
    # via pandas
urllib3==2.4.0
    # via requests
wcwidth==0.2.13
    # via prompt-toolkit
zarr==3.0.7
    # via -r ../../requirements.in