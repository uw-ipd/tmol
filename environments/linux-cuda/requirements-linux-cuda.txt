#
# This file is autogenerated by pip-compile with Python 3.11
# by the following command:
#
#    pip-compile --cert=None --client-cert=None --index-url=None --no-emit-index-url --pip-args=None ../../requirements.in
#
astor==0.8.1
    # via -r ../../requirements.in
asttokens==3.0.0
    # via stack-data
attrs==25.3.0
    # via
    #   -r ../../requirements.in
    #   attrs-strict
    #   cattrs
    #   hypothesis
attrs-strict==1.0.1
    # via -r ../../requirements.in
cattrs==25.2.0
    # via -r ../../requirements.in
certifi==2025.8.3
    # via requests
charset-normalizer==3.4.3
    # via requests
decorator==5.2.1
    # via
    #   -r ../../requirements.in
    #   ipython
executing==2.2.1
    # via stack-data
filelock==3.19.1
    # via torch
flexcache==0.3
    # via pint
flexparser==0.4
    # via pint
frozendict==2.4.6
    # via -r ../../requirements.in
fsspec==2025.9.0
    # via torch
hypothesis==6.140.2
    # via -r ../../requirements.in
idna==3.10
    # via requests
ipython==9.5.0
    # via -r ../../requirements.in
ipython-pygments-lexers==1.1.1
    # via ipython
jedi==0.19.2
    # via ipython
jinja2==3.1.6
    # via torch
llvmlite==0.45.0
    # via numba
markupsafe==3.0.2
    # via jinja2
matplotlib-inline==0.1.7
    # via ipython
mpmath==1.3.0
    # via sympy
mypy-extensions==1.1.0
    # via typing-inspect
networkx==3.5
    # via
    #   -r ../../requirements.in
    #   torch
ninja==1.13.0
    # via -r ../../requirements.in
numba==0.62.0
    # via sparse
numpy==2.3.3
    # via
    #   -r ../../requirements.in
    #   numba
    #   pandas
    #   scipy
    #   sparse
nvidia-cublas-cu12==12.8.4.1
    # via
    #   nvidia-cudnn-cu12
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cuda-cupti-cu12==12.8.90
    # via torch
nvidia-cuda-nvrtc-cu12==12.8.93
    # via torch
nvidia-cuda-runtime-cu12==12.8.90
    # via torch
nvidia-cudnn-cu12==9.10.2.21
    # via torch
nvidia-cufft-cu12==11.3.3.83
    # via torch
nvidia-cufile-cu12==1.13.1.3
    # via torch
nvidia-curand-cu12==10.3.9.90
    # via torch
nvidia-cusolver-cu12==11.7.3.90
    # via torch
nvidia-cusparse-cu12==12.5.8.93
    # via
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cusparselt-cu12==0.7.1
    # via torch
nvidia-nccl-cu12==2.27.3
    # via torch
nvidia-nvjitlink-cu12==12.8.93
    # via
    #   nvidia-cufft-cu12
    #   nvidia-cusolver-cu12
    #   nvidia-cusparse-cu12
    #   torch
nvidia-nvtx-cu12==12.8.90
    # via torch
pandas==2.3.2
    # via -r ../../requirements.in
parso==0.8.5
    # via jedi
pexpect==4.9.0
    # via ipython
pint==0.25
    # via -r ../../requirements.in
platformdirs==4.4.0
    # via pint
prompt-toolkit==3.0.52
    # via ipython
psutil==7.1.0
    # via -r ../../requirements.in
ptyprocess==0.7.0
    # via pexpect
pure-eval==0.2.3
    # via stack-data
pyarrow==21.0.0
    # via -r ../../requirements.in
pygments==2.19.2
    # via
    #   ipython
    #   ipython-pygments-lexers
python-dateutil==2.9.0.post0
    # via pandas
pytz==2025.2
    # via pandas
pyyaml==6.0.2
    # via -r ../../requirements.in
requests==2.32.5
    # via -r ../../requirements.in
scipy==1.16.2
    # via -r ../../requirements.in
six==1.17.0
    # via python-dateutil
sortedcontainers==2.4.0
    # via hypothesis
sparse==0.17.0
    # via -r ../../requirements.in
stack-data==0.6.3
    # via ipython
sympy==1.14.0
    # via torch
toolz==1.0.0
    # via -r ../../requirements.in
torch==2.8.0
    # via -r ../../requirements.in
traitlets==5.14.3
    # via
    #   ipython
    #   matplotlib-inline
triton==3.4.0
    # via torch
typing-extensions==4.15.0
    # via
    #   -r ../../requirements.in
    #   cattrs
    #   flexcache
    #   flexparser
    #   ipython
    #   pint
    #   torch
    #   typing-inspect
typing-inspect==0.9.0
    # via -r ../../requirements.in
tzdata==2025.2
    # via pandas
urllib3==2.5.0
    # via requests
wcwidth==0.2.14
    # via prompt-toolkit

