

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tmol.score.common.stack_condense &mdash; TMol 0.0.0-187-g4c860a97 documentation</title>
  

  
  
  
  
    <link rel="canonical" href="http://tmol.uw.ipd.edu/_modules/tmol/score/common/stack_condense.html"/>
  

  
  <script type="text/javascript" src="../../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../../../../',
              VERSION:'0.0.0-187-g4c860a97',
              LANGUAGE:'None',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> TMol
          

          
          </a>

          
            
            
              <div class="version">
                0.0.0-187-g4c860a97
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../architecture.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../datatypes.html">Datatypes</a></li>
</ul>
<p class="caption"><span class="caption-text">Packages</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../apidoc/tmol.system.html">tmol.system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../apidoc/tmol.score.html">tmol.score</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../apidoc/tmol.database.html">tmol.database</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../apidoc/tmol.kinematics.html">tmol.kinematics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../apidoc/tmol.numeric.html">tmol.numeric</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../apidoc/tmol.types.html">tmol.types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../apidoc/tmol.utility.html">tmol.utility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../apidoc/tmol.io.html">tmol.io</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../apidoc/tmol.viewer.html">tmol.viewer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../apidoc/tmol.support.html">tmol.support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../apidoc/tmol.extern.html">tmol.extern</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">TMol</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
          <li><a href="../../score.html">tmol.score</a> &raquo;</li>
        
      <li>tmol.score.common.stack_condense</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for tmol.score.common.stack_condense</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">tmol.types.torch</span> <span class="k">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">tmol.types.array</span> <span class="k">import</span> <span class="n">NDArray</span>

<span class="kn">from</span> <span class="nn">tmol.types.functional</span> <span class="k">import</span> <span class="n">validate_args</span>

<span class="c1">##################################################################</span>
<span class="c1"># For operations on stacked systems, we have to deal with the fact</span>
<span class="c1"># that systems will almost always be of different sizes. The</span>
<span class="c1"># operations in this file aim to shuffle data into a form where</span>
<span class="c1"># the entries that &quot;hand off the end&quot; of a row in a stack (but</span>
<span class="c1"># which have to be there because another row of a stack is</span>
<span class="c1"># longer) are shifted to the higher indices (the &quot;right&quot; if you</span>
<span class="c1"># draw the stack on paper) and the entries that correspond</span>
<span class="c1"># to real data are all shifted to the lower indices (the &quot;left&quot;).</span>
<span class="c1">#</span>
<span class="c1"># Call tensors that arrange their data this way &quot;condensed.&quot;</span>
<span class="c1">#</span>
<span class="c1"># The convention used here is to mark all non-real entries</span>
<span class="c1"># with a sentinel of -1</span>
<span class="c1">#</span>
<span class="c1"># The functions here will help:</span>
<span class="c1"># 1. map a 2D tensor with sporadically placed sentineled entries</span>
<span class="c1">#    into a condensed tensor, and</span>
<span class="c1"># 2. index into one tensor into a condensed output tensor</span>


<div class="viewcode-block" id="condense_numpy_inds"><a class="viewcode-back" href="../../../../apidoc/tmol.score.common.stack_condense.html#tmol.score.common.stack_condense.condense_numpy_inds">[docs]</a><span class="k">def</span> <span class="nf">condense_numpy_inds</span><span class="p">(</span><span class="n">selection</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">(</span><span class="nb">bool</span><span class="p">)[:,</span> <span class="p">:]):</span>
    <span class="sd">&quot;&quot;&quot;Given a two dimensional boolean tensor, create</span>
<span class="sd">    an output tensor holding the column indices of the non-zero</span>
<span class="sd">    entries for each row. Pad out the extra entries</span>
<span class="sd">    in any given row that do not correspond to a selected</span>
<span class="sd">    entry with a sentinel of -1.</span>

<span class="sd">    e.g. if the input is</span>

<span class="sd">    [[ 0  1  0  1]</span>
<span class="sd">    [  1  1  0  1]]</span>

<span class="sd">    then the output will be</span>

<span class="sd">    [[ 1  3 -1]</span>
<span class="sd">    [  0  1  3]]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">nstacks</span> <span class="o">=</span> <span class="n">selection</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">nz_selection</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">selection</span><span class="p">)</span>
    <span class="n">nkeep</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">selection</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">nstacks</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">max_keep</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">nkeep</span><span class="p">)</span>
    <span class="n">inds</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">nstacks</span><span class="p">,</span> <span class="n">max_keep</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_keep</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_keep</span><span class="p">))</span>
    <span class="n">lowinds</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">&lt;</span> <span class="n">nkeep</span>

    <span class="n">inds</span><span class="p">[</span><span class="n">lowinds</span><span class="p">]</span> <span class="o">=</span> <span class="n">nz_selection</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">inds</span></div>


<div class="viewcode-block" id="condense_torch_inds"><a class="viewcode-back" href="../../../../apidoc/tmol.score.common.stack_condense.html#tmol.score.common.stack_condense.condense_torch_inds">[docs]</a><span class="k">def</span> <span class="nf">condense_torch_inds</span><span class="p">(</span><span class="n">selection</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="nb">bool</span><span class="p">)[:,</span> <span class="p">:],</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Given a two dimensional boolean tensor, create</span>
<span class="sd">    an output tensor holding the column indices of the non-zero</span>
<span class="sd">    entries for each row. Pad out the extra entries</span>
<span class="sd">    in any given row that do not correspond to a selected</span>
<span class="sd">    entry with a sentinel of -1.</span>

<span class="sd">    e.g. if the input is</span>
<span class="sd">    [[ 0  1  0  1]</span>
<span class="sd">    [  1  1  0  1]]</span>
<span class="sd">    then the output will be</span>
<span class="sd">    [[ 1  3 -1]</span>
<span class="sd">    [  0  1  3]]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">nstacks</span> <span class="o">=</span> <span class="n">selection</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">nz_selection</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">selection</span><span class="p">)</span>
    <span class="n">nkeep</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">selection</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">((</span><span class="n">nstacks</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">max_keep</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">nkeep</span><span class="p">)</span>
    <span class="n">inds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">nstacks</span><span class="p">,</span> <span class="n">max_keep</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_keep</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
        <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_keep</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">lowinds</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">&lt;</span> <span class="n">nkeep</span>

    <span class="n">inds</span><span class="p">[</span><span class="n">lowinds</span><span class="p">]</span> <span class="o">=</span> <span class="n">nz_selection</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">inds</span></div>


<div class="viewcode-block" id="take_values_w_sentineled_index"><a class="viewcode-back" href="../../../../apidoc/tmol.score.common.stack_condense.html#tmol.score.common.stack_condense.take_values_w_sentineled_index">[docs]</a><span class="nd">@validate_args</span>
<span class="k">def</span> <span class="nf">take_values_w_sentineled_index</span><span class="p">(</span>
    <span class="n">value_tensor</span><span class="p">,</span> <span class="n">sentineled_index_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)[:,</span> <span class="p">:],</span> <span class="n">default_fill</span><span class="o">=-</span><span class="mi">1</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The sentinel in the sentineled_index_tensor is -1: the positions</span>
<span class="sd">    with the sentinel value should not be used as an index into the</span>
<span class="sd">    value tensor. This function returns a tensor of the same shape as</span>
<span class="sd">    the sentineled_index_tensor with a dtype of the value tensor.</span>

<span class="sd">    E.g. if the value tensor is [10 11 12 13 14 15]</span>
<span class="sd">    and the sentineled_index_tensor is</span>

<span class="sd">    [[ 2 1 2 5 -1]</span>
<span class="sd">    [  1 4 1 5  2]]</span>

<span class="sd">    then the output tensor will be</span>

<span class="sd">    [[ 12 11 12 15 -1]</span>
<span class="sd">    [  11 14 11 15  12]]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>

    <span class="n">output_value_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
        <span class="n">sentineled_index_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">default_fill</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">value_tensor</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">value_tensor</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">output_value_tensor</span><span class="p">[</span><span class="n">sentineled_index_tensor</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">value_tensor</span><span class="p">[</span>
        <span class="n">sentineled_index_tensor</span><span class="p">[</span><span class="n">sentineled_index_tensor</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="n">output_value_tensor</span></div>


<div class="viewcode-block" id="take_values_w_sentineled_index_and_dest"><a class="viewcode-back" href="../../../../apidoc/tmol.score.common.stack_condense.html#tmol.score.common.stack_condense.take_values_w_sentineled_index_and_dest">[docs]</a><span class="nd">@validate_args</span>
<span class="k">def</span> <span class="nf">take_values_w_sentineled_index_and_dest</span><span class="p">(</span>
    <span class="n">value_tensor</span><span class="p">,</span>
    <span class="n">sentineled_index_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)[:,</span> <span class="p">:],</span>
    <span class="n">sentineled_dest_tensor</span><span class="p">,</span>
    <span class="n">default_fill</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The sentinel in the sentineled_index_tensor is -1: the positions</span>
<span class="sd">    with the sentinel value should not be used as an index into the</span>
<span class="sd">    value tensor. The sentinel in the sentineled_dest_tensor is also</span>
<span class="sd">    -1: the positions with the sentinel value should not be written</span>
<span class="sd">    to in the output tensor. This function returns a tensor of the</span>
<span class="sd">    same shape as the sentineled_dest_tensor with a dtype of the</span>
<span class="sd">    value tensor, which is indexed into using the</span>
<span class="sd">    sentineled_index_tensor. The values in the sentineled_dest_tensor</span>
<span class="sd">    do not matter except where they are -1.</span>

<span class="sd">    E.g. if the value tensor is [10 11 12 13 14 15],</span>
<span class="sd">    the sentineled_index_tensor is</span>
<span class="sd">    [[ 2 -1  2  5 -1]</span>
<span class="sd">    [  1  4 -1  5  2]],</span>
<span class="sd">    and the sentineled_dest_tensor is</span>
<span class="sd">    [[ 1  1  1 -1]</span>
<span class="sd">    [  1  1  1  1]]</span>

<span class="sd">    then the output tensor will be</span>
<span class="sd">    [[ 12 12 15 -1]</span>
<span class="sd">    [  11 14 15 12]]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentineled_dest_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>

    <span class="n">output_value_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
        <span class="n">sentineled_dest_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">default_fill</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">value_tensor</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">value_tensor</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">output_value_tensor</span><span class="p">[</span><span class="n">sentineled_dest_tensor</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">value_tensor</span><span class="p">[</span>
        <span class="n">sentineled_index_tensor</span><span class="p">[</span><span class="n">sentineled_index_tensor</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="n">output_value_tensor</span></div>


<div class="viewcode-block" id="take_values_w_sentineled_dest"><a class="viewcode-back" href="../../../../apidoc/tmol.score.common.stack_condense.html#tmol.score.common.stack_condense.take_values_w_sentineled_dest">[docs]</a><span class="k">def</span> <span class="nf">take_values_w_sentineled_dest</span><span class="p">(</span>
    <span class="n">value_tensor</span><span class="p">,</span>
    <span class="n">values_to_take</span><span class="p">,</span>  <span class="c1"># boolean mask tensor</span>
    <span class="n">sentineled_dest_tensor</span><span class="p">,</span>
    <span class="n">default_fill</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Take a subset of the values from the value_tensor indicated by</span>
<span class="sd">    the boolean values_to_take tensor, and write them into an output</span>
<span class="sd">    tensor in a shape with non-negative-one values in the</span>
<span class="sd">    sentineled_dest_tensor. There need to be as many &quot;true&quot; values in</span>
<span class="sd">    the values_to_take tensor as they are non-negative-one values</span>
<span class="sd">    in the sentineled_dest_tensor.</span>

<span class="sd">    E.g. if the value tensor is</span>
<span class="sd">    [[10 11 12 13 14],</span>
<span class="sd">    [ 20 21 22 23 24]]</span>
<span class="sd">    the values_to_take tensor is</span>
<span class="sd">    [[ 1  0  1  1  0]</span>
<span class="sd">    [  1  1  0  1  1]],</span>
<span class="sd">    and the sentineled_dest_tensor is</span>
<span class="sd">    [[ 1  1  1 -1]</span>
<span class="sd">    [  1  1  1  1]]</span>

<span class="sd">    then the output tensor will be</span>
<span class="sd">    [[10 12 13 -1]</span>
<span class="sd">    [ 20 21 23 24]]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">assert</span> <span class="n">value_tensor</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">values_to_take</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">output_value_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
        <span class="n">sentineled_dest_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">default_fill</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">value_tensor</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">value_tensor</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">output_value_tensor</span><span class="p">[</span><span class="n">sentineled_dest_tensor</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">value_tensor</span><span class="p">[</span><span class="n">values_to_take</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">output_value_tensor</span></div>


<div class="viewcode-block" id="condense_subset"><a class="viewcode-back" href="../../../../apidoc/tmol.score.common.stack_condense.html#tmol.score.common.stack_condense.condense_subset">[docs]</a><span class="k">def</span> <span class="nf">condense_subset</span><span class="p">(</span>
    <span class="n">values</span><span class="p">,</span>  <span class="c1"># three dimensional tensor of values</span>
    <span class="n">values_to_keep</span><span class="p">,</span>  <span class="c1"># two dimensional tensor</span>
    <span class="n">default_fill</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Take the values for the third dimension of the 3D &quot;values&quot; tensor,</span>
<span class="sd">    (condensing them), corresponding to the positions indicated by</span>
<span class="sd">    the values_to_keep tensor.</span>

<span class="sd">    E.g. if the values tensor is</span>
<span class="sd">    [[[10 10] [11 11] [12 12] [13 13] [14 14]],</span>
<span class="sd">    [ [20 20] [21 21] [22 22] [23 23] [24 24]]]</span>
<span class="sd">    the values_to_keep tensor is</span>
<span class="sd">    [[1 0 1 1 0]</span>
<span class="sd">    [ 1 1 0 1 1]]</span>

<span class="sd">    then the output tensor will be</span>
<span class="sd">    [[ [10 10] [12 12] [13 13] [ -1 -1]]</span>
<span class="sd">    [  [20 20] [21 21] [23 23] [24 24]]]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">values_to_keep</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="k">assert</span> <span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">values_to_keep</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">cinds</span> <span class="o">=</span> <span class="n">condense_torch_inds</span><span class="p">(</span><span class="n">values_to_keep</span><span class="p">,</span> <span class="n">values_to_keep</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">selected_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
        <span class="p">(</span><span class="n">cinds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cinds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span>
        <span class="n">default_fill</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">values</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">values</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">nz_cinds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">cinds</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">selected_values</span><span class="p">[</span><span class="n">nz_cinds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">nz_cinds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span>
        <span class="n">nz_cinds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cinds</span><span class="p">[</span><span class="n">cinds</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="p">:</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="n">selected_values</span></div>


<div class="viewcode-block" id="take_condensed_3d_subset"><a class="viewcode-back" href="../../../../apidoc/tmol.score.common.stack_condense.html#tmol.score.common.stack_condense.take_condensed_3d_subset">[docs]</a><span class="nd">@validate_args</span>
<span class="k">def</span> <span class="nf">take_condensed_3d_subset</span><span class="p">(</span>
    <span class="n">values</span><span class="p">,</span>  <span class="c1"># 3D Tensor of arbitrary dtype</span>
    <span class="n">condensed_inds_to_keep</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)[:,</span> <span class="p">:],</span>
    <span class="n">condensed_dst_inds</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)[:,</span> <span class="mi">2</span><span class="p">],</span>
    <span class="n">default_fill</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Take the values for the third dimension of the 3D &quot;values&quot; tensor,</span>
<span class="sd">    at the positions indicated by the &quot;condensed_inds_to_keep&quot; tensor,</span>
<span class="sd">    and writing them to the indices indicated by the &quot;condensed_dst_inds&quot;.</span>
<span class="sd">    This function is equivalent to the above &quot;condense_subset&quot; function</span>
<span class="sd">    if that function&#39;s &quot;values_to_keep&quot; tensor is converted to the</span>
<span class="sd">    inputs to this function with the following operations:</span>

<span class="sd">    condensed_inds_to_keep = condense_torch_inds(values_to_keep != -1, device)</span>
<span class="sd">    condensed_dst_inds = torch.nonzero(inds_to_keep != -1)</span>

<span class="sd">    This function is more efficient if you intend to use the</span>
<span class="sd">    &quot;condensed_inds_to_keep&quot; or the &quot;condensed_dst_inds&quot; tensors multiple</span>
<span class="sd">    times.</span>

<span class="sd">    E.g. if the values tensor is</span>
<span class="sd">    [[[10 10] [11 11] [12 12] [13 13] [14 14]],</span>
<span class="sd">    [ [20 20] [21 21] [22 22] [23 23] [24 24]]]</span>
<span class="sd">    the condensed_inds_to_keep tensor is</span>
<span class="sd">    [[ 0 -1  2  3]</span>
<span class="sd">    [  4  3  2  4]],</span>
<span class="sd">    and the condensed_dest_tensor is</span>
<span class="sd">    [[ 0 0]</span>
<span class="sd">    [  0 1]</span>
<span class="sd">    [  0 2]</span>
<span class="sd">    [  1 0]</span>
<span class="sd">    [  1 1]</span>
<span class="sd">    [  1 2]</span>
<span class="sd">    [  1 3]]</span>

<span class="sd">    then the output tensor will be</span>
<span class="sd">    [[ [10 10] [12 12] [13 13] [ -1 -1]]</span>
<span class="sd">    [  [24 24] [23 23] [22 22] [24 24]]]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>

    <span class="n">keep</span> <span class="o">=</span> <span class="n">condensed_inds_to_keep</span>
    <span class="n">dst</span> <span class="o">=</span> <span class="n">condensed_dst_inds</span>

    <span class="n">subset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
        <span class="p">(</span><span class="n">keep</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">3</span><span class="p">]),</span>
        <span class="n">default_fill</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">values</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">values</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">subset</span><span class="p">[</span><span class="n">dst</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dst</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">dst</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">keep</span><span class="p">[</span><span class="n">keep</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]</span>
    <span class="k">return</span> <span class="n">subset</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, TMol Contributers

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>